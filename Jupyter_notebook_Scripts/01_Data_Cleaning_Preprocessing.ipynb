{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc721beb-3cbf-4c5c-b5c8-50723ee6cccc",
   "metadata": {},
   "source": [
    "# 1. Data Import and Initial Validation\n",
    "### The first step in our analysis is to acquire the data and perform a thorough initial check.\n",
    "\n",
    "- Import the data from its source into a Pandas DataFrame, the primary structure we'll use for analysis.\n",
    "- Validate the data's basic integrity: We need to ensure there are no immediate red flags, such as widespread missing values or columns with entirely incorrect data types.\n",
    "- Establish a baseline understanding of the dataset's structure, including its size and the variables it contains.\n",
    "- Check for duplicated rows in the data\n",
    "\n",
    "I will load the data from the CSV file marketing_data.csv and then use a combination of Pandas methods to inspect health of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a3264035-2b49-45a0-b36d-6eeebbf78baf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Year_Birth', 'Education', 'Marital_Status', ' Income ',\n",
      "       'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', 'MntWines',\n",
      "       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
      "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
      "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
      "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
      "       'AcceptedCmp2', 'Response', 'Complain', 'Country'],\n",
      "      dtype='object')\n",
      "****************************************************************\n",
      "Number of duplicated rows in the data is : 0\n",
      "****************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 28 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   2240 non-null   int64 \n",
      " 1   Year_Birth           2240 non-null   int64 \n",
      " 2   Education            2240 non-null   object\n",
      " 3   Marital_Status       2240 non-null   object\n",
      " 4   Income               2216 non-null   object\n",
      " 5   Kidhome              2240 non-null   int64 \n",
      " 6   Teenhome             2240 non-null   int64 \n",
      " 7   Dt_Customer          2240 non-null   object\n",
      " 8   Recency              2240 non-null   int64 \n",
      " 9   MntWines             2240 non-null   int64 \n",
      " 10  MntFruits            2240 non-null   int64 \n",
      " 11  MntMeatProducts      2240 non-null   int64 \n",
      " 12  MntFishProducts      2240 non-null   int64 \n",
      " 13  MntSweetProducts     2240 non-null   int64 \n",
      " 14  MntGoldProds         2240 non-null   int64 \n",
      " 15  NumDealsPurchases    2240 non-null   int64 \n",
      " 16  NumWebPurchases      2240 non-null   int64 \n",
      " 17  NumCatalogPurchases  2240 non-null   int64 \n",
      " 18  NumStorePurchases    2240 non-null   int64 \n",
      " 19  NumWebVisitsMonth    2240 non-null   int64 \n",
      " 20  AcceptedCmp3         2240 non-null   int64 \n",
      " 21  AcceptedCmp4         2240 non-null   int64 \n",
      " 22  AcceptedCmp5         2240 non-null   int64 \n",
      " 23  AcceptedCmp1         2240 non-null   int64 \n",
      " 24  AcceptedCmp2         2240 non-null   int64 \n",
      " 25  Response             2240 non-null   int64 \n",
      " 26  Complain             2240 non-null   int64 \n",
      " 27  Country              2240 non-null   object\n",
      "dtypes: int64(23), object(5)\n",
      "memory usage: 490.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#importing \"marketing_data\" data to jupyter\n",
    "df=pd.read_csv('data/raw/marketing_data.csv')\n",
    "#checking keys of the data\n",
    "print(df.keys())\n",
    "#Remving spaces before and after the columns keys in data\n",
    "df.columns = df.columns.str.strip()\n",
    "#checking values in each column\n",
    "duplicate_rows_num = df.duplicated().sum()\n",
    "print('****************************************************************')\n",
    "print(f\"Number of duplicated rows in the data is : {duplicate_rows_num}\")\n",
    "print('****************************************************************')\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a6b4b-2e9d-431b-a2db-4637cdef5208",
   "metadata": {},
   "source": [
    "Based on the result from above cell, spaces in name of varaibles (keys) have been removed. \n",
    "Inital inspection showed:\n",
    "- 5 columns (`Dt_Customer`, `Education`, `Marital_Status`, `country`, `Income`) have `object` type, which might be mixing data types.\n",
    "- No columns have missing values\n",
    "- No duplicated rows found in the data\n",
    "- Values in `Income` column starts with $, which needs to turn to numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a564ea-ba13-4b54-a575-a3e858f124a3",
   "metadata": {},
   "source": [
    "# 2. Data type cnoversion\n",
    "### Since data type are not appropraite for 5 columns as shown above, we need to convert them as belwo. \n",
    "- Conver one column (Dt_Customer) to `datetime` type.\n",
    "- Convert three columns (`Education`, \"Marital_Status` and `Country`) into `category` type.\n",
    "- Remove `$` in the begining of values of `Income` column. then, check the data.\n",
    "- Conver Income` column into numeric type.\n",
    "- Inspection entire tabel after data type conversion! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54f39dbf-ef3b-461f-9300-eeec37535f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Series name: Dt_Customer\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "2240 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 17.6 KB\n",
      "None\n",
      "ID                              int64\n",
      "Year_Birth                      int64\n",
      "Education                    category\n",
      "Marital_Status               category\n",
      "Income                        float64\n",
      "Kidhome                         int64\n",
      "Teenhome                        int64\n",
      "Dt_Customer            datetime64[ns]\n",
      "Recency                         int64\n",
      "MntWines                        int64\n",
      "MntFruits                       int64\n",
      "MntMeatProducts                 int64\n",
      "MntFishProducts                 int64\n",
      "MntSweetProducts                int64\n",
      "MntGoldProds                    int64\n",
      "NumDealsPurchases               int64\n",
      "NumWebPurchases                 int64\n",
      "NumCatalogPurchases             int64\n",
      "NumStorePurchases               int64\n",
      "NumWebVisitsMonth               int64\n",
      "AcceptedCmp3                    int64\n",
      "AcceptedCmp4                    int64\n",
      "AcceptedCmp5                    int64\n",
      "AcceptedCmp1                    int64\n",
      "AcceptedCmp2                    int64\n",
      "Response                        int64\n",
      "Complain                        int64\n",
      "Country                      category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#convert object columns (Dt_Customer, Education, Marital_Status, Country, Income)\n",
    "df[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"], format=\"%m/%d/%y\", errors=\"coerce\")\n",
    "print(df[\"Dt_Customer\"].info())\n",
    "df[\"Education\"] = df[\"Education\"].astype(\"category\")\n",
    "df[\"Marital_Status\"] = df[\"Marital_Status\"].astype(\"category\")\n",
    "df[\"Country\"] = df[\"Country\"].astype(\"category\")\n",
    "#remove $ from begining of data\n",
    "df['Income']= df['Income'].str.replace('$', '')\n",
    "#remove , from data\n",
    "df['Income']= df['Income'].str.replace(',', '')\n",
    "#Transfer string type of data in income to numeric type and replace missing values or invalid data to NaN\n",
    "df['Income'] = pd.to_numeric(df['Income'], errors='coerce')\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ea02e-6bef-4ce8-b3a1-fb4e3169f2c2",
   "metadata": {},
   "source": [
    "According to results of above cell: \n",
    "- After data type conversion, `Income` column has 24 missing values, which need to be filled by average income of similar education and marital status. \n",
    "- Data in columns (`Marital_Status`, `Education` and `Country`) are good and no missing values\n",
    "- Data in columns  `Dt_Customer`  are datetime and has no missing values now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726e458-ab90-4b3e-b3b7-4dff8d5b7e15",
   "metadata": {},
   "source": [
    "# 3. Handling missing values of columns \n",
    "Since `Income` column is the only columns has missing value. I need to handle only this column step by step as below. \n",
    "- Calculate avergae income for people from same Marital Status and Education by groupby \n",
    "- Find rows with missing values in `Income` column\n",
    "- Fill missing values in Income column using the calculted values\n",
    "- Inspect data after one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e88609a6-e604-464f-a95f-930075ea1c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of missing value for each column\n",
      "ID                      0\n",
      "Year_Birth              0\n",
      "Education               0\n",
      "Marital_Status          0\n",
      "Income                 24\n",
      "Kidhome                 0\n",
      "Teenhome                0\n",
      "Dt_Customer             0\n",
      "Recency                 0\n",
      "MntWines                0\n",
      "MntFruits               0\n",
      "MntMeatProducts         0\n",
      "MntFishProducts         0\n",
      "MntSweetProducts        0\n",
      "MntGoldProds            0\n",
      "NumDealsPurchases       0\n",
      "NumWebPurchases         0\n",
      "NumCatalogPurchases     0\n",
      "NumStorePurchases       0\n",
      "NumWebVisitsMonth       0\n",
      "AcceptedCmp3            0\n",
      "AcceptedCmp4            0\n",
      "AcceptedCmp5            0\n",
      "AcceptedCmp1            0\n",
      "AcceptedCmp2            0\n",
      "Response                0\n",
      "Complain                0\n",
      "Country                 0\n",
      "dtype: int64\n",
      "*****************************************************************************\n",
      "Total number of missing value after filling for each column\n",
      "ID                     0\n",
      "Year_Birth             0\n",
      "Education              0\n",
      "Marital_Status         0\n",
      "Income                 0\n",
      "Kidhome                0\n",
      "Teenhome               0\n",
      "Dt_Customer            0\n",
      "Recency                0\n",
      "MntWines               0\n",
      "MntFruits              0\n",
      "MntMeatProducts        0\n",
      "MntFishProducts        0\n",
      "MntSweetProducts       0\n",
      "MntGoldProds           0\n",
      "NumDealsPurchases      0\n",
      "NumWebPurchases        0\n",
      "NumCatalogPurchases    0\n",
      "NumStorePurchases      0\n",
      "NumWebVisitsMonth      0\n",
      "AcceptedCmp3           0\n",
      "AcceptedCmp4           0\n",
      "AcceptedCmp5           0\n",
      "AcceptedCmp1           0\n",
      "AcceptedCmp2           0\n",
      "Response               0\n",
      "Complain               0\n",
      "Country                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Finding missing values in all columns of the data\n",
    "print(\"Total number of missing value for each column\")\n",
    "print(df.isna().sum())\n",
    "#finding missing values in income column of the data\n",
    "missing_values = df['Income'].isnull()\n",
    "missing_values_Income=df[missing_values][['ID','Income','Marital_Status','Education']]\n",
    "print('*****************************************************************************')\n",
    "#print(missing_values_Income)\n",
    "df_droped = df.dropna(subset=['Income'])\n",
    "# Calculate average value of income for same Marital_Status and Education\n",
    "avergae_mat_Edu=df_droped[['Income','Marital_Status','Education']].groupby(['Marital_Status','Education'], observed=True).mean(numeric_only=True)\n",
    "#filling mising values in income columns by average income of the same education and martial status\n",
    "missing_equvalent_avg=pd.merge(missing_values_Income,avergae_mat_Edu,on=['Marital_Status','Education'],how='left')\n",
    "missing_equvalent_avg=missing_equvalent_avg.drop(columns='Income_x')\n",
    "missing_equvalent_avg=missing_equvalent_avg.rename(columns={'Income_y': 'Income'})\n",
    "df = df.merge(\n",
    "    missing_equvalent_avg[['ID', 'Income']], \n",
    "    on='ID', \n",
    "    how='left', \n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "# Fill missing values with the new calculated values\n",
    "df['Income'] = df['Income_new'].combine_first(df['Income'])\n",
    "df = df.drop('Income_new', axis=1)\n",
    "print(\"Total number of missing value after filling for each column\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7262f0fd-5da7-4654-be4b-a8b00f1ac91c",
   "metadata": {},
   "source": [
    "After handling missing values, inspection showed that there is no missing values in any column. Thus, data is clean and ready for analysis/modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e8d49-b961-4dc5-ae5c-fc888ff71666",
   "metadata": {},
   "source": [
    "# 4. Define new columns and calculate values of the columns\n",
    "For our analysis, we need to define and calculate four new columns including `Number_children`, `Age`, `total_spending`, and `total_purchases`.\n",
    "- `Number_children` is defined by adding `Kidhome` and `Teenhome`\n",
    "- `Age` is defined by subtracting current date from `Year_Birth`\n",
    "- `total_spending` is defined by adding all expenses\n",
    "- `total_purchases` is defined by adding all purchases\n",
    "\n",
    "At the end, we need to check data frame to see the new columns are added by printing 5 first rows of the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2f0f9eff-c1d8-4341-9a03-3c8c88c45ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************print 5 rows of data (number of children,age, toal spending and total purchase for customers)\n",
      "      ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0   1826        1970  Graduation       Divorced  84835.0        0         0   \n",
      "1      1        1961  Graduation         Single  57091.0        0         0   \n",
      "2  10476        1958  Graduation        Married  67267.0        0         1   \n",
      "3   1386        1967  Graduation       Together  32474.0        1         1   \n",
      "4   5371        1989  Graduation         Single  21474.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  AcceptedCmp5  AcceptedCmp1  \\\n",
      "0  2014-06-16        0       189  ...             0             0   \n",
      "1  2014-06-15        0       464  ...             0             0   \n",
      "2  2014-05-13        0       134  ...             0             0   \n",
      "3  2014-05-11        0        10  ...             0             0   \n",
      "4  2014-04-08        0         6  ...             0             0   \n",
      "\n",
      "   AcceptedCmp2  Response  Complain  Country  Number_children  Age  \\\n",
      "0             0         1         0       SP                0   55   \n",
      "1             1         1         0       CA                0   64   \n",
      "2             0         0         0       US                1   67   \n",
      "3             0         0         0      AUS                2   58   \n",
      "4             0         1         0       SP                1   36   \n",
      "\n",
      "   total_spending  total_purchases  \n",
      "0            1190               14  \n",
      "1             577               17  \n",
      "2             251               10  \n",
      "3              11                3  \n",
      "4              91                6  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "tody_date=date.today()\n",
    "#Create varaibles for number of children, age, toal spending, and total purchase for customers and added them to df\n",
    "df['Number_children']=df['Kidhome']+df['Teenhome']\n",
    "df['Age']=tody_date.year-df['Year_Birth']\n",
    "df['total_spending']=df['MntWines']+df['MntFruits']+df['MntMeatProducts']+df['MntFishProducts']+df['MntSweetProducts']+df['MntGoldProds']\n",
    "df['total_purchases']=df['NumWebPurchases']+df['NumCatalogPurchases']+df['NumStorePurchases']\n",
    "print('*****************print 5 rows of data (number of children,age, toal spending and total purchase for customers)')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ad8ba-45fe-4ff5-8b4e-70819049b7c8",
   "metadata": {},
   "source": [
    "Insepction of the data by printing 5 first rows of the data, showed that the four new columns have been defined and added to the data correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f940c8c-4c70-4fd9-80e2-7d8fa931d4d2",
   "metadata": {},
   "source": [
    "# 5. Encode categorical variables using ordinal encoding and one-hot encoding.\n",
    "- Encode categorical variables inclusing `Education` using ordinal encoding \n",
    "- Apply onehot encoding to variable`Country` and `Marital_Status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "28fba93c-21b2-4a0e-812c-180151942e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************shows first five rows of the datasets after converting the columns (Education, Marital_Status, Country)************\n",
      "      ID  Year_Birth   Income  Kidhome  Teenhome Dt_Customer  Recency  \\\n",
      "0   1826        1970  84835.0        0         0  2014-06-16        0   \n",
      "1      1        1961  57091.0        0         0  2014-06-15        0   \n",
      "2  10476        1958  67267.0        0         1  2014-05-13        0   \n",
      "3   1386        1967  32474.0        1         1  2014-05-11        0   \n",
      "4   5371        1989  21474.0        1         0  2014-04-08        0   \n",
      "\n",
      "   MntWines  MntFruits  MntMeatProducts  ...  Marital_Status_Widow  \\\n",
      "0       189        104              379  ...                   0.0   \n",
      "1       464          5               64  ...                   0.0   \n",
      "2       134         11               59  ...                   0.0   \n",
      "3        10          0                1  ...                   0.0   \n",
      "4         6         16               24  ...                   0.0   \n",
      "\n",
      "   Marital_Status_YOLO  Country_AUS  Country_CA  Country_GER  Country_IND  \\\n",
      "0                  0.0          0.0         0.0          0.0          0.0   \n",
      "1                  0.0          0.0         1.0          0.0          0.0   \n",
      "2                  0.0          0.0         0.0          0.0          0.0   \n",
      "3                  0.0          1.0         0.0          0.0          0.0   \n",
      "4                  0.0          0.0         0.0          0.0          0.0   \n",
      "\n",
      "   Country_ME  Country_SA  Country_SP  Country_US  \n",
      "0         0.0         0.0         1.0         0.0  \n",
      "1         0.0         0.0         0.0         0.0  \n",
      "2         0.0         0.0         0.0         1.0  \n",
      "3         0.0         0.0         0.0         0.0  \n",
      "4         0.0         0.0         1.0         0.0  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      " Number of rows in the converted dataset: 2240\n",
      " Number of columns in the converted dataset: 46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#ordinal encoding for variable('Education')\n",
    "#define levels and apply ordinal encoding to 'Education'\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['2n Cycle', 'Basic', 'Graduation', 'Master', 'PhD']])\n",
    "df['Ordinal'] = ordinal_encoder.fit_transform(df[['Education']])\n",
    "df.drop('Education', axis=1, inplace=True)\n",
    "df.rename(columns={'Ordinal': 'Education'}, inplace=True)\n",
    "#onehot encoding for variable('Marital_Status')\n",
    "# Marital_Status column drops and 8 new columns are created (\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoded = onehot_encoder.fit_transform(df[['Marital_Status']])\n",
    "df_onehot = pd.DataFrame(onehot_encoded.toarray(), columns=onehot_encoder.get_feature_names_out(['Marital_Status']))\n",
    "onehot_encoder2 = OneHotEncoder()\n",
    "onehot_encoded2 = onehot_encoder2.fit_transform(df[['Country']])\n",
    "df_onehot2 = pd.DataFrame(onehot_encoded2.toarray(), columns=onehot_encoder2.get_feature_names_out(['Country']))\n",
    "df.drop('Marital_Status', axis=1, inplace=True)\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df = pd.concat([df, df_onehot, df_onehot2], axis=1)\n",
    "print('******************shows first five rows of the datasets after converting the columns (Education, Marital_Status, Country)************')\n",
    "print(df.head(5))\n",
    "print(f\" Number of rows in the converted dataset: {df.shape[0]}\")\n",
    "print(f\" Number of columns in the converted dataset: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20d784-b967-4659-9416-51f570760e46",
   "metadata": {},
   "source": [
    "- `Education` column converted to ordinal column values from 1 to 5\n",
    "- `Marital_Status` column converted into Marital_Status_Absurd, Marital_Status_Alone, Marital_Status_Divorced, Marital_Status_Married, Marital_Status_Single, Marital_Status_Together, Marital_Status_Widow, Marital_Status_YOLO\n",
    "- `Country` column converted into 8 columns including Country_AUS, Country_CA, Country_GER, Country_IND, Country_ME, Country_SA, Country_SP, Country_US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275956f-164e-4adc-af05-83986cad343f",
   "metadata": {},
   "source": [
    "# 6. Save cleaned data into a file.\n",
    "Next juypter notebook will use this data and do second part of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b217f5e-72f4-453d-9273-b13c9e95d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data/interim/cleaned_data.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
